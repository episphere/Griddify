{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from skimage.draw import disk\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.image import resize\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def create_mask_from_json(json_data, shape):\n",
    "    mask = np.zeros(shape, dtype=np.float32)\n",
    "    for item in json_data:\n",
    "        rr, cc = disk((item['y'], item['x']), item['radius'], shape=shape)\n",
    "        mask[rr, cc] = 1.0\n",
    "    return mask\n",
    "\n",
    "def resize_labels(labels, original_size, new_size):\n",
    "    scale_x = new_size[1] / original_size[1]\n",
    "    scale_y = new_size[0] / original_size[0]\n",
    "    resized_labels = []\n",
    "    for label in labels:\n",
    "        resized_label = {\n",
    "            'x': label['x'] * scale_x,\n",
    "            'y': label['y'] * scale_y,\n",
    "            'radius': label['radius'] * scale_x  # Assuming uniform scaling in x and y\n",
    "        }\n",
    "        resized_labels.append(resized_label)\n",
    "    return resized_labels\n",
    "\n",
    "def load_images_and_labels(image_paths, label_dir, new_size):\n",
    "    original_size = (1024, 1024)  # Original size of the images and labels\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        # Extract filename without extension to match with the label\n",
    "        base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        label_file = os.path.join(label_dir, base_filename + '.json')\n",
    "\n",
    "        # Load and resize image\n",
    "        image = img_to_array(load_img(image_path, color_mode='rgb', target_size=new_size))\n",
    "        images.append(image / 255.0)  # Normalizing to [0, 1]\n",
    "\n",
    "        # Load and resize corresponding label\n",
    "        with open(label_file, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "        resized_json_data = resize_labels(json_data, original_size, new_size)\n",
    "        mask = create_mask_from_json(resized_json_data, shape=new_size)\n",
    "        masks.append(mask)\n",
    "\n",
    "    return np.array(images), np.array(masks).reshape(-1, *new_size, 1)\n",
    "\n",
    "\n",
    "\n",
    "def create_loocv_folds(image_files, augmented_image_dir, num_augmentations = 20):\n",
    "    folds = []\n",
    "    n = len(image_files)\n",
    "\n",
    "    for i in range(n):\n",
    "        test_image = image_files[i]\n",
    "        \n",
    "        # Ensure validation images are different from the test image and rotate them\n",
    "        val_indices = [(i + 1) % n, (i + 2) % n]\n",
    "        validation_images = [image_files[j] for j in val_indices]\n",
    "\n",
    "        # Remaining images for training, excluding the test and validation images\n",
    "        train_images = [img for idx, img in enumerate(image_files) if idx not in [i, val_indices[0], val_indices[1]]]\n",
    "\n",
    "        # Augmented images for training\n",
    "        augmented_train_images = [os.path.join(augmented_image_dir, os.path.basename(img).replace('.png', f'_aug_{k}.png')) \n",
    "                                  for img in train_images for k in range(num_augmentations)]\n",
    "\n",
    "        folds.append((augmented_train_images, [test_image], validation_images))\n",
    "\n",
    "    return folds\n",
    "\n",
    "def create_10fold_cv_folds(image_files, augmented_image_dir, n_splits=10, num_augmentations = 20):\n",
    "    # Initialize the KFold mechanism\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    folds = []\n",
    "    n = len(image_files)\n",
    "    \n",
    "    for train_val_indices, test_indices in kf.split(image_files):\n",
    "        # Separate the original dataset into training+validation and testing sets\n",
    "        test_images = [image_files[i] for i in test_indices]\n",
    "        \n",
    "        # The training+validation set (will further split into actual train and validation sets)\n",
    "        train_val_images = [image_files[i] for i in train_val_indices]\n",
    "        \n",
    "        # We take the first 90% of the train_val_indices for training and the remaining 10% for validation\n",
    "        # Adjust the percentage as needed for training vs. validation split\n",
    "        split_idx = int(len(train_val_images) * 0.9)\n",
    "        train_images, validation_images = train_val_images[:split_idx], train_val_images[split_idx:]\n",
    "        \n",
    "        # Augmented images for training\n",
    "        augmented_train_images = [os.path.join(augmented_image_dir, os.path.basename(img).replace('.png', f'_aug_{k}.png')) \n",
    "                                  for img in train_images for k in range(num_augmentations)]\n",
    "        \n",
    "        folds.append((augmented_train_images, test_images, validation_images))\n",
    "    \n",
    "    return folds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D, BatchNormalization, Activation, SeparableConv2D\n",
    "\n",
    "# def conv_block(input_tensor, num_filters, kernel_size=3, do_batch_norm=True):\n",
    "#     # A conv block consists of two convolutions, each followed by a batch normalization and a relu activation.\n",
    "#     x = Conv2D(num_filters, kernel_size, padding='same', kernel_initializer='he_normal')(input_tensor)\n",
    "#     if do_batch_norm:\n",
    "#         x = BatchNormalization()(x)\n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "#     x = Conv2D(num_filters, kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
    "#     if do_batch_norm:\n",
    "#         x = BatchNormalization()(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     return x\n",
    "\n",
    "def conv_block(input_tensor, num_filters, kernel_size=3, do_batch_norm=True):\n",
    "    x = SeparableConv2D(num_filters, kernel_size, padding='same', kernel_initializer='he_normal')(input_tensor)\n",
    "    if do_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = SeparableConv2D(num_filters, kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
    "    if do_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def unet(input_size=(512, 512, 3), num_filters=16, depth=2, dropout=0.5, batch_norm=True):\n",
    "    # INPUT LAYER\n",
    "    inputs = Input(input_size)\n",
    "    # CONTRACTING PATH\n",
    "    conv_blocks = []\n",
    "    x = inputs\n",
    "    for i in range(depth):\n",
    "        x = conv_block(x, num_filters * (2**i), do_batch_norm=batch_norm)\n",
    "        conv_blocks.append(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        if dropout:\n",
    "            x = Dropout(dropout)(x)\n",
    "\n",
    "    # BOTTLENECK\n",
    "    x = conv_block(x, num_filters * (2**(depth)), do_batch_norm=batch_norm)\n",
    "    \n",
    "    # EXPANSIVE PATH\n",
    "    for i in reversed(range(depth)):\n",
    "        num_filters_exp = num_filters * (2**i)\n",
    "        x = UpSampling2D(size=(2, 2))(x)\n",
    "        x = concatenate([x, conv_blocks[i]], axis=3)\n",
    "        x = conv_block(x, num_filters_exp, do_batch_norm=batch_norm)\n",
    "\n",
    "    # FINAL CONVOLUTION\n",
    "    output = Conv2D(1, 1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Define a Learning Rate Schedule\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 0:\n",
    "        return lr\n",
    "    elif epoch < 10 and epoch%2 == 0:\n",
    "        return lr\n",
    "    elif epoch < 20 and epoch%2 == 0:\n",
    "        return lr * tf.math.exp(-0.2)\n",
    "    elif epoch > 30:\n",
    "        return lr * tf.math.exp(-0.5)\n",
    "    else:\n",
    "        return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "log_dir = \"./tensorboard_logs\"\n",
    "\n",
    "def weighted_binary_crossentropy(zero_weight, one_weight):\n",
    "    def loss(y_true, y_pred):\n",
    "        bce = K.binary_crossentropy(y_true, y_pred)\n",
    "        weight_vector = y_true * one_weight + (1. - y_true) * zero_weight\n",
    "        weighted_bce = weight_vector * bce\n",
    "\n",
    "        return K.mean(weighted_bce)\n",
    "    return loss\n",
    "\n",
    "def train_unet(model, train_images, train_masks, val_images, val_masks, epochs=300, batch_size=32, checkpoint_path='pixel_cores.hdf5'):\n",
    "    # Define the custom loss function\n",
    "    custom_loss = weighted_binary_crossentropy(zero_weight=1, one_weight=1)\n",
    "\n",
    "    # Check if a previous checkpoint exists\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Loading weights from checkpoint: {checkpoint_path}\")\n",
    "        # Load the model with the custom loss function\n",
    "        model = load_model(checkpoint_path, custom_objects={'loss': custom_loss})\n",
    "    else:\n",
    "        print(\"No checkpoint found. Starting training from scratch.\")\n",
    "\n",
    "    # Compile the model with the custom loss function\n",
    "    model.compile(optimizer=Adam(learning_rate=5e-8), loss=custom_loss, metrics=['AUC', 'accuracy', 'Precision', 'Recall'])\n",
    "    model_checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    \n",
    "    # Define the TensorBoard callback\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    # Define the EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
    "\n",
    "    # Fit the model with the given training and validation data\n",
    "    history = model.fit(\n",
    "        x=train_images, \n",
    "        y=train_masks, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs, \n",
    "        verbose=1, \n",
    "        validation_data=(val_images, val_masks), \n",
    "        callbacks=[model_checkpoint, tensorboard_callback, lr_scheduler, early_stopping]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import csv  # Import the csv module\n",
    "\n",
    "original_image_dir = './TMA_WSI_Padded_PNGs'\n",
    "augmented_image_dir = './augmented_images'\n",
    "original_label_dir = './TMA_WSI_Labels_updated'\n",
    "augmented_label_dir = './augmented_labels'\n",
    "\n",
    "# Use list comprehension to create the list of file paths\n",
    "original_image_files = [os.path.join(original_image_dir, file) for file in sorted(\n",
    "    os.listdir(original_image_dir)) if file.endswith('.png')]\n",
    "\n",
    "folds = create_10fold_cv_folds(original_image_files, augmented_image_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./TMA_WSI_Padded_PNGs/61.png',\n",
       " './TMA_WSI_Padded_PNGs/62.png',\n",
       " './TMA_WSI_Padded_PNGs/63.png',\n",
       " './TMA_WSI_Padded_PNGs/7.png',\n",
       " './TMA_WSI_Padded_PNGs/8.png',\n",
       " './TMA_WSI_Padded_PNGs/9.png']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds[2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_18 (InputLayer)       [(None, 512, 512, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " separable_conv2d_150 (Sepa  (None, 512, 512, 16)         91        ['input_18[0][0]']            \n",
      " rableConv2D)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_170 (B  (None, 512, 512, 16)         64        ['separable_conv2d_150[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_170 (Activation  (None, 512, 512, 16)         0         ['batch_normalization_170[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " separable_conv2d_151 (Sepa  (None, 512, 512, 16)         416       ['activation_170[0][0]']      \n",
      " rableConv2D)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_171 (B  (None, 512, 512, 16)         64        ['separable_conv2d_151[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_171 (Activation  (None, 512, 512, 16)         0         ['batch_normalization_171[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_34 (MaxPooli  (None, 256, 256, 16)         0         ['activation_171[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_34 (Dropout)        (None, 256, 256, 16)         0         ['max_pooling2d_34[0][0]']    \n",
      "                                                                                                  \n",
      " separable_conv2d_152 (Sepa  (None, 256, 256, 32)         688       ['dropout_34[0][0]']          \n",
      " rableConv2D)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_172 (B  (None, 256, 256, 32)         128       ['separable_conv2d_152[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_172 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_172[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " separable_conv2d_153 (Sepa  (None, 256, 256, 32)         1344      ['activation_172[0][0]']      \n",
      " rableConv2D)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_173 (B  (None, 256, 256, 32)         128       ['separable_conv2d_153[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_173 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_173[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_35 (MaxPooli  (None, 128, 128, 32)         0         ['activation_173[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_35 (Dropout)        (None, 128, 128, 32)         0         ['max_pooling2d_35[0][0]']    \n",
      "                                                                                                  \n",
      " separable_conv2d_154 (Sepa  (None, 128, 128, 64)         2400      ['dropout_35[0][0]']          \n",
      " rableConv2D)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_174 (B  (None, 128, 128, 64)         256       ['separable_conv2d_154[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_174 (Activation  (None, 128, 128, 64)         0         ['batch_normalization_174[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " separable_conv2d_155 (Sepa  (None, 128, 128, 64)         4736      ['activation_174[0][0]']      \n",
      " rableConv2D)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_175 (B  (None, 128, 128, 64)         256       ['separable_conv2d_155[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_175 (Activation  (None, 128, 128, 64)         0         ['batch_normalization_175[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " up_sampling2d_34 (UpSampli  (None, 256, 256, 64)         0         ['activation_175[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_34 (Concatenat  (None, 256, 256, 96)         0         ['up_sampling2d_34[0][0]',    \n",
      " e)                                                                  'activation_173[0][0]']      \n",
      "                                                                                                  \n",
      " separable_conv2d_156 (Sepa  (None, 256, 256, 32)         3968      ['concatenate_34[0][0]']      \n",
      " rableConv2D)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_176 (B  (None, 256, 256, 32)         128       ['separable_conv2d_156[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_176 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_176[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " separable_conv2d_157 (Sepa  (None, 256, 256, 32)         1344      ['activation_176[0][0]']      \n",
      " rableConv2D)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_177 (B  (None, 256, 256, 32)         128       ['separable_conv2d_157[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_177 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_177[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " up_sampling2d_35 (UpSampli  (None, 512, 512, 32)         0         ['activation_177[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_35 (Concatenat  (None, 512, 512, 48)         0         ['up_sampling2d_35[0][0]',    \n",
      " e)                                                                  'activation_171[0][0]']      \n",
      "                                                                                                  \n",
      " separable_conv2d_158 (Sepa  (None, 512, 512, 16)         1216      ['concatenate_35[0][0]']      \n",
      " rableConv2D)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_178 (B  (None, 512, 512, 16)         64        ['separable_conv2d_158[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_178 (Activation  (None, 512, 512, 16)         0         ['batch_normalization_178[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " separable_conv2d_159 (Sepa  (None, 512, 512, 16)         416       ['activation_178[0][0]']      \n",
      " rableConv2D)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_179 (B  (None, 512, 512, 16)         64        ['separable_conv2d_159[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_179 (Activation  (None, 512, 512, 16)         0         ['batch_normalization_179[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)          (None, 512, 512, 1)          17        ['activation_179[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 17916 (69.98 KB)\n",
      "Trainable params: 17276 (67.48 KB)\n",
      "Non-trainable params: 640 (2.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = unet()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 598ms/step - loss: 0.1366 - auc: 0.9797 - accuracy: 0.9471 - precision: 0.8938 - recall: 0.8151\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.3942 - auc: 0.8826 - accuracy: 0.8654 - precision: 0.8782 - recall: 0.3788\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.1387 - auc: 0.9783 - accuracy: 0.9484 - precision: 0.8872 - recall: 0.8472\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.1536 - auc: 0.9779 - accuracy: 0.9431 - precision: 0.8716 - recall: 0.8665\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 0.2331 - auc: 0.9760 - accuracy: 0.8762 - precision: 0.5864 - recall: 0.9323\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.2086 - auc: 0.9679 - accuracy: 0.9181 - precision: 0.9210 - recall: 0.6386\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.2153 - auc: 0.9750 - accuracy: 0.9413 - precision: 0.9232 - recall: 0.7586\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.1576 - auc: 0.9844 - accuracy: 0.9436 - precision: 0.8512 - recall: 0.9026\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.1298 - auc: 0.9802 - accuracy: 0.9522 - precision: 0.9468 - recall: 0.7333\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.2305 - auc: 0.9623 - accuracy: 0.9274 - precision: 0.8850 - recall: 0.7709\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_file = 'model_evaluation_results.csv'\n",
    "\n",
    "# Open the CSV file in append mode\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Fold', 'Loss', 'AUC', 'Accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "    # Iterate over each fold\n",
    "    for i, fold in enumerate(folds):\n",
    "        # Load the checkpointed model for the fold\n",
    "        model_path = f\"pixel_core_fold_{i+1}.hdf5\"\n",
    "        loaded_model = tf.keras.models.load_model(model_path, custom_objects={'loss': weighted_binary_crossentropy(zero_weight=1, one_weight=1)})\n",
    "\n",
    "        # Unpack the fold\n",
    "        train_image, test_image, val_images = fold\n",
    "\n",
    "        # Load the test images and masks\n",
    "        test_images, test_masks = load_images_and_labels(test_image, original_label_dir, (512,512))\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        loss, auc, accuracy, precision, recall = loaded_model.evaluate(test_images, test_masks)\n",
    "\n",
    "        # Write the evaluation metrics to the CSV file\n",
    "        writer.writerow([i+1, loss, auc, accuracy, precision, recall])\n",
    "    \n",
    "\n",
    "        # Flush the changes to the CSV file\n",
    "        file.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from checkpoint: pixel_core_fold_2.hdf5\n",
      "Epoch 1/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1500 - auc: 0.9769 - accuracy: 0.9471 - precision: 0.8794 - recall: 0.8464 \n",
      "Epoch 1: val_loss improved from inf to 0.42193, saving model to pixel_core_fold_2.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 384s 12s/step - loss: 0.1500 - auc: 0.9769 - accuracy: 0.9471 - precision: 0.8794 - recall: 0.8464 - val_loss: 0.4219 - val_auc: 0.9213 - val_accuracy: 0.8695 - val_precision: 0.5485 - val_recall: 0.7893 - lr: 5.0000e-07\n",
      "Epoch 2/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1496 - auc: 0.9772 - accuracy: 0.9473 - precision: 0.8798 - recall: 0.8469 \n",
      "Epoch 2: val_loss did not improve from 0.42193\n",
      "32/32 [==============================] - 383s 12s/step - loss: 0.1496 - auc: 0.9772 - accuracy: 0.9473 - precision: 0.8798 - recall: 0.8469 - val_loss: 0.5376 - val_auc: 0.9139 - val_accuracy: 0.8668 - val_precision: 0.5358 - val_recall: 0.9077 - lr: 5.0000e-07\n",
      "Epoch 3/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1498 - auc: 0.9772 - accuracy: 0.9471 - precision: 0.8793 - recall: 0.8467 \n",
      "Epoch 3: val_loss did not improve from 0.42193\n",
      "32/32 [==============================] - 377s 12s/step - loss: 0.1498 - auc: 0.9772 - accuracy: 0.9471 - precision: 0.8793 - recall: 0.8467 - val_loss: 0.6500 - val_auc: 0.9031 - val_accuracy: 0.7768 - val_precision: 0.3996 - val_recall: 0.9393 - lr: 5.0000e-07\n",
      "Epoch 4/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1499 - auc: 0.9770 - accuracy: 0.9471 - precision: 0.8795 - recall: 0.8466 \n",
      "Epoch 4: val_loss did not improve from 0.42193\n",
      "32/32 [==============================] - 356s 11s/step - loss: 0.1499 - auc: 0.9770 - accuracy: 0.9471 - precision: 0.8795 - recall: 0.8466 - val_loss: 0.7196 - val_auc: 0.8983 - val_accuracy: 0.7166 - val_precision: 0.3423 - val_recall: 0.9426 - lr: 5.0000e-07\n",
      "Epoch 5/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1491 - auc: 0.9775 - accuracy: 0.9474 - precision: 0.8798 - recall: 0.8476 \n",
      "Epoch 5: val_loss did not improve from 0.42193\n",
      "32/32 [==============================] - 365s 11s/step - loss: 0.1491 - auc: 0.9775 - accuracy: 0.9474 - precision: 0.8798 - recall: 0.8476 - val_loss: 0.7248 - val_auc: 0.9007 - val_accuracy: 0.7251 - val_precision: 0.3487 - val_recall: 0.9369 - lr: 5.0000e-07\n",
      "Epoch 6/150\n",
      "13/32 [===========>..................] - ETA: 3:56 - loss: 0.1463 - auc: 0.9787 - accuracy: 0.9487 - precision: 0.8778 - recall: 0.8515"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m model \u001b[38;5;241m=\u001b[39m unet()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_unet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpixel_core_fold_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mindex\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.hdf5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[1;32m     48\u001b[0m loss, auc, accuracy, precision, recall \u001b[38;5;241m=\u001b[39m trained_model\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[1;32m     49\u001b[0m     test_images, test_masks)\n",
      "Cell \u001b[0;32mIn[65], line 61\u001b[0m, in \u001b[0;36mtrain_unet\u001b[0;34m(model, train_images, train_masks, val_images, val_masks, epochs, batch_size, checkpoint_path)\u001b[0m\n\u001b[1;32m     58\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Fit the model with the given training and validation data\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_masks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Assuming the existence of these functions and variables:\n",
    "# load_images_and_labels, folds, augmented_label_dir, original_label_dir, unet, train_unet\n",
    "\n",
    "# Evaluation metrics initialization\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "new_size = (512, 512)\n",
    "\n",
    "start_fold = 2  # Set this to your desired starting fold number\n",
    "\n",
    "# Open a CSV file to write the results\n",
    "with open('model_evaluation_results.csv', mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Check if the file is empty by seeking to the end and getting the position\n",
    "    file.seek(0, os.SEEK_END)\n",
    "    if file.tell() == 0:\n",
    "        # File is empty, write the header\n",
    "        writer.writerow(['Fold', 'Loss', 'AUC', 'Accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "    file.flush() \n",
    "    indices = range(start_fold, 11)  # Adjusted to start from start_fold\n",
    "    # Iterate over each fold\n",
    "    for index in indices:\n",
    "        fold = folds[index - 1]\n",
    "        augmented_train_images, test_image, validation_images = fold\n",
    "\n",
    "        # Load and preprocess images and labels\n",
    "        train_images, train_masks = load_images_and_labels(\n",
    "            augmented_train_images, augmented_label_dir, new_size)\n",
    "        test_images, test_masks = load_images_and_labels(\n",
    "            test_image, original_label_dir, new_size)\n",
    "        val_images, val_masks = load_images_and_labels(\n",
    "            validation_images, original_label_dir, new_size)\n",
    "\n",
    "        # Create a new instance of the model\n",
    "        model = unet()\n",
    "\n",
    "        # Train the model\n",
    "        trained_model = train_unet(model, train_images, train_masks, val_images, val_masks, 150, 32, f\"pixel_core_fold_{index}.hdf5\")\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        loss, auc, accuracy, precision, recall = trained_model.evaluate(\n",
    "            test_images, test_masks)\n",
    "\n",
    "        # Store the evaluation metrics\n",
    "        auc_scores.append(auc)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "\n",
    "        # Write the fold results to the CSV file\n",
    "        writer.writerow([index, loss, auc, accuracy, precision, recall])\n",
    "        file.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Loss</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.50000</td>\n",
       "      <td>0.199782</td>\n",
       "      <td>0.966438</td>\n",
       "      <td>0.926263</td>\n",
       "      <td>0.864441</td>\n",
       "      <td>0.764396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.02765</td>\n",
       "      <td>0.079384</td>\n",
       "      <td>0.030139</td>\n",
       "      <td>0.031071</td>\n",
       "      <td>0.101622</td>\n",
       "      <td>0.160807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.129794</td>\n",
       "      <td>0.882597</td>\n",
       "      <td>0.865384</td>\n",
       "      <td>0.586440</td>\n",
       "      <td>0.378800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.25000</td>\n",
       "      <td>0.142416</td>\n",
       "      <td>0.969656</td>\n",
       "      <td>0.920398</td>\n",
       "      <td>0.873218</td>\n",
       "      <td>0.739637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.50000</td>\n",
       "      <td>0.183095</td>\n",
       "      <td>0.976972</td>\n",
       "      <td>0.942170</td>\n",
       "      <td>0.886104</td>\n",
       "      <td>0.793000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.75000</td>\n",
       "      <td>0.226656</td>\n",
       "      <td>0.979393</td>\n",
       "      <td>0.946190</td>\n",
       "      <td>0.914200</td>\n",
       "      <td>0.861691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.00000</td>\n",
       "      <td>0.394235</td>\n",
       "      <td>0.984359</td>\n",
       "      <td>0.952200</td>\n",
       "      <td>0.946821</td>\n",
       "      <td>0.932339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Fold       Loss        AUC   Accuracy  Precision     Recall\n",
       "count  10.00000  10.000000  10.000000  10.000000  10.000000  10.000000\n",
       "mean    5.50000   0.199782   0.966438   0.926263   0.864441   0.764396\n",
       "std     3.02765   0.079384   0.030139   0.031071   0.101622   0.160807\n",
       "min     1.00000   0.129794   0.882597   0.865384   0.586440   0.378800\n",
       "25%     3.25000   0.142416   0.969656   0.920398   0.873218   0.739637\n",
       "50%     5.50000   0.183095   0.976972   0.942170   0.886104   0.793000\n",
       "75%     7.75000   0.226656   0.979393   0.946190   0.914200   0.861691\n",
       "max    10.00000   0.394235   0.984359   0.952200   0.946821   0.932339"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.read_csv('model_evaluation_results.csv') \n",
    "\n",
    "results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model and the folds training and validation data from the 9th fold\n",
    "\n",
    "# Load the checkpointed model for the fold\n",
    "model_path = \"pixel_core_fold_9.hdf5\"\n",
    "loaded_model = tf.keras.models.load_model(model_path, custom_objects={'loss': weighted_binary_crossentropy(zero_weight=1, one_weight=1)})\n",
    "\n",
    "# Combine the validation and training sets for the 9th fold. Ensure that we're using the augmented versions of both the training and validation images\n",
    "\n",
    "# Unpack the fold\n",
    "train_images, test_image, val_images = folds[8]\n",
    "\n",
    "# Load the training and validation images and masks\n",
    "train_images, train_masks = load_images_and_labels(train_images, augmented_label_dir, (512,512))\n",
    "\n",
    "# Load the augmented versions of the validation images and masks\n",
    "augmented_val_images = [os.path.join(augmented_image_dir, os.path.basename(img).replace('.png', f'_aug_{k}.png')) for img in val_images for k in range(20)]\n",
    "\n",
    "augmented_val_images, augmented_val_masks = load_images_and_labels(augmented_val_images, augmented_label_dir, (512,512))\n",
    "\n",
    "\n",
    "# Train the model on the combined training and validation sets\n",
    "trained_model = train_unet(loaded_model, np.concatenate([train_images, augmented_val_images]), np.concatenate([train_masks, augmented_val_masks]), test_images, test_masks, 150, 32, f\"pixel_core_fold_9_combined.hdf5\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, auc, accuracy, precision, recall = trained_model.evaluate(test_images, test_masks)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
