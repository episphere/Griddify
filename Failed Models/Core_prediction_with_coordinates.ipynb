{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from skimage.draw import disk\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, Activation, BatchNormalization, Input, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Maximum number of cores we expect in any image\n",
    "MAX_CORES = 256  # Adjust this number based on your dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_array(json_data):\n",
    "    labels = []\n",
    "    for item in json_data:\n",
    "        labels.append([item['x'], item['y'], item['radius']])\n",
    "    # If there are fewer cores than MAX_CORES, we pad the remaining values with -1\n",
    "    while len(labels) < MAX_CORES:\n",
    "        labels.append([-1, -1, -1])  # Padding\n",
    "    labels_flat = np.array(labels).flatten()\n",
    "    # Normalize and flatten the labels to be between 0 and 1, except for padding values which remain -1\n",
    "    for i in range(0, len(labels_flat), 3):\n",
    "        if labels_flat[i] != -1:\n",
    "            labels_flat[i] /= 1024\n",
    "            labels_flat[i+1] /= 1024\n",
    "            labels_flat[i+2] /= 1024\n",
    "    return labels_flat\n",
    "\n",
    "def load_images_and_labels(image_dir, label_dir):\n",
    "    image_files = [os.path.join(image_dir, file) for file in sorted(os.listdir(image_dir)) if file.endswith('.png')]\n",
    "    label_files = [os.path.join(label_dir, file) for file in sorted(os.listdir(label_dir)) if file.endswith('.json')]\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for image_file, label_file in zip(image_files, label_files):\n",
    "        # Load image\n",
    "        image = img_to_array(load_img(image_file, color_mode='rgb'))\n",
    "        images.append(image / 255.0)  # Normalize the image\n",
    "\n",
    "        # Load corresponding label\n",
    "        with open(label_file, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "        label = create_label_array(json_data)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "# Usage\n",
    "image_dir = './TMA_WSI_Padded_PNGs'\n",
    "label_dir = './TMA_WSI_Labels_updated'\n",
    "images, labels = load_images_and_labels(image_dir, label_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.67484799,  0.9584839 ,  0.02050781,  0.63689222,  0.95836265,\n",
       "        0.02050781,  0.51830787,  0.95696212,  0.02050781,  0.47422477,\n",
       "        0.95246469,  0.02050781,  0.4461997 ,  0.95300336,  0.02050781,\n",
       "        0.40591982,  0.95212648,  0.02050781,  0.33213435,  0.95209927,\n",
       "        0.02050781,  0.29367329,  0.94923416,  0.02050781,  0.17910226,\n",
       "        0.94507225,  0.02050781,  0.2550067 ,  0.94649648,  0.02050781,\n",
       "        0.21700379,  0.94631954,  0.02050781,  0.14083668,  0.93906828,\n",
       "        0.02050781,  0.48365068,  0.91360363,  0.02050781,  0.17984267,\n",
       "        0.90260694,  0.02050781,  0.78911114,  0.88022895,  0.02050781,\n",
       "        0.67867021,  0.88054992,  0.02050781,  0.64090349,  0.87714357,\n",
       "        0.02050781,  0.25540466,  0.86533323,  0.02050781,  0.21561345,\n",
       "        0.86383388,  0.02050781,  0.17871942,  0.85931477,  0.02050781,\n",
       "        0.05869408,  0.85494121,  0.02050781,  0.86796468,  0.84733176,\n",
       "        0.02050781,  0.82914161,  0.84566085,  0.02050781,  0.68129128,\n",
       "        0.84158529,  0.02050781,  0.64167911,  0.833364  ,  0.02050781,\n",
       "        0.60786765,  0.83290866,  0.02050781,  0.33977506,  0.83127216,\n",
       "        0.02050781,  0.41411811,  0.82984037,  0.02050781,  0.30016843,\n",
       "        0.82758484,  0.02050781,  0.4865055 ,  0.82847068,  0.02050781,\n",
       "        0.25521428,  0.82753033,  0.02050781,  0.21633658,  0.81980133,\n",
       "        0.02050781,  0.09868283,  0.81698516,  0.02050781,  0.05630518,\n",
       "        0.81520062,  0.02050781,  0.79287535,  0.80470707,  0.02050781,\n",
       "        0.907056  ,  0.80656797,  0.02050781,  0.86794123,  0.80438953,\n",
       "        0.02050781,  0.75486334,  0.80243132,  0.02050781,  0.68216117,\n",
       "        0.79692911,  0.02050781,  0.64131349,  0.7950864 ,  0.02050781,\n",
       "        0.40475418,  0.78867234,  0.02050781,  0.25173783,  0.78802725,\n",
       "        0.02050781,  0.49151208,  0.78706808,  0.02050781,  0.21400072,\n",
       "        0.77814948,  0.02050781,  0.17354946,  0.77729041,  0.02050781,\n",
       "        0.13377101,  0.77691076,  0.02050781,  0.09521599,  0.77505989,\n",
       "        0.02050781,  0.9490968 ,  0.76836704,  0.02050781,  0.79380541,\n",
       "        0.76118675,  0.02050781,  0.68401307,  0.75549388,  0.02050781,\n",
       "        0.40764342,  0.74628087,  0.02050781,  0.44859372,  0.74605302,\n",
       "        0.02050781,  0.21501093,  0.73965219,  0.02050781,  0.25708301,\n",
       "        0.74005518,  0.02050781,  0.9091527 ,  0.72504534,  0.02050781,\n",
       "        0.83224708,  0.72128135,  0.02050781,  0.79339234,  0.72054855,\n",
       "        0.02050781,  0.86895375,  0.72130702,  0.02050781,  0.64129337,\n",
       "        0.71199253,  0.02050781,  0.67839278,  0.71048924,  0.02050781,\n",
       "        0.60256334,  0.70881426,  0.02050781,  0.44589485,  0.7042846 ,\n",
       "        0.02050781,  0.4051928 ,  0.70371358,  0.02050781,  0.09614857,\n",
       "        0.69502644,  0.02050781,  0.21928481,  0.69696866,  0.02050781,\n",
       "        0.05793987,  0.69535667,  0.02050781,  0.79374744,  0.67986042,\n",
       "        0.02050781,  0.60800168,  0.67050903,  0.02050781,  0.68545309,\n",
       "        0.67169382,  0.02050781,  0.64635368,  0.66998044,  0.02050781,\n",
       "        0.4504143 ,  0.66769167,  0.02050781,  0.40963788,  0.66439425,\n",
       "        0.02050781,  0.06563972,  0.65904294,  0.02050781,  0.13673493,\n",
       "        0.65621368,  0.02050781,  0.09776362,  0.65669777,  0.02050781,\n",
       "        0.34038089,  0.65774631,  0.02050781,  0.17920225,  0.65546228,\n",
       "        0.02050781,  0.30068204,  0.65454409,  0.02050781,  0.95383992,\n",
       "        0.64281718,  0.02050781,  0.7503258 ,  0.64069103,  0.02050781,\n",
       "        0.86976903,  0.64088785,  0.02050781,  0.79096767,  0.63965459,\n",
       "        0.02050781,  0.44655436,  0.62450815,  0.02050781,  0.33926603,\n",
       "        0.61552962,  0.02050781,  0.14040031,  0.61388814,  0.02050781,\n",
       "        0.87267681,  0.60234432,  0.02050781,  0.2561874 ,  0.6110104 ,\n",
       "        0.02050781,  0.83365384,  0.59991465,  0.02050781,  0.75365942,\n",
       "        0.60057445,  0.02050781,  0.79462825,  0.59935461,  0.02050781,\n",
       "        0.75296068,  0.55653537,  0.02050781,  0.68582922,  0.54915204,\n",
       "        0.02050781,  0.64859541,  0.54602676,  0.02050781,  0.60974146,\n",
       "        0.54170604,  0.02050781,  0.4893286 ,  0.53892227,  0.02050781,\n",
       "        0.4497323 ,  0.53964781,  0.02050781,  0.21896951,  0.53817385,\n",
       "        0.02050781,  0.18084241,  0.53769585,  0.02050781,  0.14305835,\n",
       "        0.53762847,  0.02050781,  0.40844591,  0.53941627,  0.02050781,\n",
       "        0.25868962,  0.53750094,  0.02050781,  0.33729354,  0.53677329,\n",
       "        0.02050781,  0.29627792,  0.53677329,  0.02050781,  0.95206446,\n",
       "        0.52973075,  0.02050781,  0.79215988,  0.52221767,  0.02050781,\n",
       "        0.87416073,  0.52206509,  0.02050781,  0.91065778,  0.52406639,\n",
       "        0.02050781,  0.68882469,  0.50811984,  0.02050781,  0.18520725,\n",
       "        0.49699054,  0.02050781,  0.94779845,  0.49365885,  0.02050781,\n",
       "        0.41072064,  0.49756683,  0.02050781,  0.26738251,  0.49650498,\n",
       "        0.02050781,  0.14620061,  0.49768011,  0.02050781,  0.49209842,\n",
       "        0.49423882,  0.02050781,  0.57336402,  0.49595609,  0.02050781,\n",
       "        0.226132  ,  0.49681579,  0.02050781,  0.53156805,  0.49222081,\n",
       "        0.02050781,  0.90976314,  0.48395544,  0.02050781,  0.8728932 ,\n",
       "        0.47647615,  0.02050781,  0.78889723,  0.48086572,  0.02050781,\n",
       "        0.74696245,  0.47856069,  0.02050781,  0.10813705,  0.46127876,\n",
       "        0.02050781,  0.18640666,  0.45577734,  0.02050781,  0.14802529,\n",
       "        0.45848625,  0.02050781,  0.49477495,  0.44699059,  0.02050781,\n",
       "        0.41334705,  0.45458343,  0.02050781,  0.30494089,  0.45516267,\n",
       "        0.02050781,  0.57570576,  0.45039745,  0.02050781,  0.53454141,\n",
       "        0.45088119,  0.02050781,  0.06739044,  0.46494293,  0.02050781,\n",
       "        0.06543732,  0.50791168,  0.02050781,  0.06153107,  0.54599762,\n",
       "        0.02050781,  0.10157013,  0.53623199,  0.02050781,  0.05371857,\n",
       "        0.58506012,  0.02050781,  0.09766388,  0.58115387,  0.02050781,\n",
       "        0.10059357,  0.62021637,  0.02050781,  0.05664825,  0.62314606,\n",
       "        0.02050781,  0.17481232,  0.61338043,  0.02050781,  0.21192169,\n",
       "        0.61338043,  0.02050781,  0.29395294,  0.61338043,  0.02050781,\n",
       "        0.2636795 ,  0.45615387,  0.02050781,  0.22266388,  0.45713043,\n",
       "        0.02050781,  0.34082794,  0.45713043,  0.02050781,  0.13477325,\n",
       "        0.69443512,  0.02050781,  0.2949295 ,  0.70029449,  0.02050781,\n",
       "        0.33203888,  0.70029449,  0.02050781,  0.17578888,  0.81748199,\n",
       "        0.02050781,  0.14063263,  0.81748199,  0.02050781,  0.05664825,\n",
       "        0.73740387,  0.02050781,  0.05176544,  0.77646637,  0.02050781,\n",
       "        0.09864044,  0.73740387,  0.02050781,  0.13770294,  0.73545074,\n",
       "        0.02050781,  0.17383575,  0.73642731,  0.02050781,  0.29883575,\n",
       "        0.74521637,  0.02050781,  0.3418045 ,  0.74716949,  0.02050781,\n",
       "        0.33692169,  0.78916168,  0.02050781,  0.29785919,  0.78916168,\n",
       "        0.02050781,  0.29297638,  0.86826324,  0.02050781,  0.33008575,\n",
       "        0.86826324,  0.02050781,  0.21778107,  0.90732574,  0.02050781,\n",
       "        0.25098419,  0.90634918,  0.02050781,  0.29199982,  0.90927887,\n",
       "        0.02050781,  0.33301544,  0.90927887,  0.02050781,  0.13965607,\n",
       "        0.89170074,  0.02050781,  0.1386795 ,  0.86240387,  0.02050781,\n",
       "        0.09864044,  0.85752106,  0.02050781,  0.10059357,  0.90146637,\n",
       "        0.02050781,  0.05664825,  0.89756012,  0.02050781,  0.09668732,\n",
       "        0.94052887,  0.02050781,  0.17383575,  0.69931793,  0.02050781,\n",
       "        0.2168045 ,  0.65439606,  0.02050781,  0.26074982,  0.65439606,\n",
       "        0.02050781,  0.25684357,  0.70029449,  0.02050781,  0.44922638,\n",
       "        0.45810699,  0.02050781,  0.4511795 ,  0.50302887,  0.02050781,\n",
       "        0.61328888,  0.45615387,  0.02050781,  0.69043732,  0.46689606,\n",
       "        0.02050781,  0.65332794,  0.46396637,  0.02050781,  0.65039825,\n",
       "        0.50400543,  0.02050781,  0.615242  ,  0.50009918,  0.02050781,\n",
       "        0.91309357,  0.56845856,  0.02050781,  0.865242  ,  0.56259918,\n",
       "        0.02050781,  0.95215607,  0.60556793,  0.02050781,  0.91407013,\n",
       "        0.60459137,  0.02050781,  0.91114044,  0.64756012,  0.02050781,\n",
       "        0.95606232,  0.68759918,  0.02050781,  0.94727325,  0.73154449,\n",
       "        0.02050781,  0.87403107,  0.68271637,  0.02050781,  0.90821075,\n",
       "        0.68662262,  0.02050781,  0.82910919,  0.64170074,  0.02050781,\n",
       "        0.52832794,  0.52939606,  0.02050781,  0.56934357,  0.54013824,\n",
       "        0.02050781,  0.6855545 ,  0.59384918,  0.02050781,  0.65039825,\n",
       "        0.59189606,  0.02050781,  0.68360138,  0.63291168,  0.02050781,\n",
       "        0.64551544,  0.62998199,  0.02050781,  0.61231232,  0.58506012,\n",
       "        0.02050781,  0.57324982,  0.62900543,  0.02050781,  0.53028107,\n",
       "        0.62998199,  0.02050781,  0.48828888,  0.63095856,  0.02050781,\n",
       "        0.44629669,  0.58408356,  0.02050781,  0.40918732,  0.58115387,\n",
       "        0.02050781,  0.49317169,  0.66709137,  0.02050781,  0.53028107,\n",
       "        0.66709137,  0.02050781,  0.56543732,  0.67099762,  0.02050781,\n",
       "        0.56153107,  0.70908356,  0.02050781,  0.64258575,  0.75498199,\n",
       "        0.02050781,  0.60840607,  0.75400543,  0.02050781,  0.56739044,\n",
       "        0.74716949,  0.02050781,  0.52539825,  0.74619293,  0.02050781,\n",
       "        0.48731232,  0.74423981,  0.02050781,  0.44824982,  0.78916168,\n",
       "        0.02050781,  0.52735138,  0.78818512,  0.02050781,  0.56739044,\n",
       "        0.79209137,  0.02050781,  0.599617  ,  0.79599762,  0.02050781,\n",
       "        0.568367  ,  0.83408356,  0.02050781,  0.52637482,  0.82920074,\n",
       "        0.02050781,  0.44922638,  0.83017731,  0.02050781,  0.40723419,\n",
       "        0.87607574,  0.02050781,  0.443367  ,  0.87607574,  0.02050781,\n",
       "        0.48047638,  0.87412262,  0.02050781,  0.51758575,  0.87216949,\n",
       "        0.02050781,  0.55664825,  0.87802887,  0.02050781,  0.599617  ,\n",
       "        0.87900543,  0.02050781,  0.68067169,  0.92002106,  0.02050781,\n",
       "        0.63965607,  0.91904449,  0.02050781,  0.59571075,  0.96103668,\n",
       "        0.02050781,  0.55469513,  0.95713043,  0.02050781,  0.56446075,\n",
       "        0.91513824,  0.02050781,  0.52051544,  0.91318512,  0.02050781,\n",
       "        0.44239044,  0.91318512,  0.02050781,  0.4043045 ,  0.91220856,\n",
       "        0.02050781,  0.48926544,  0.58506012,  0.02050781,  0.52637482,\n",
       "        0.58603668,  0.02050781,  0.56641388,  0.58408356,  0.02050781,\n",
       "        0.40918732,  0.62216949,  0.02050781,  0.79102325,  0.84580231,\n",
       "        0.02050781,  0.75391388,  0.84482574,  0.02050781,  0.74903107,\n",
       "        0.88681793,  0.02050781,  0.7480545 ,  0.91904449,  0.02050781,\n",
       "        0.78809357,  0.91806793,  0.02050781,  0.74707794,  0.95810699,\n",
       "        0.02050781,  0.78418732,  0.95810699,  0.02050781,  0.94629669,\n",
       "        0.80673981,  0.02050781,  0.83301544,  0.48252106,  0.02050781,\n",
       "        0.833992  ,  0.52256012,  0.02050781,  0.75489044,  0.72080231,\n",
       "        0.02050781,  0.755867  ,  0.76572418,  0.02050781,  0.83301544,\n",
       "        0.76181793,  0.02050781,  0.87500763,  0.76377106,  0.02050781,\n",
       "        0.912117  ,  0.76865387,  0.02050781,  0.82910919,  0.80673981,\n",
       "        0.02050781, -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, num_filters, kernel_size=3, do_batch_norm=True):\n",
    "    # A conv block consists of two convolutions, each followed by a batch normalization and a relu activation.\n",
    "    x = Conv2D(num_filters, kernel_size, padding='same', kernel_initializer='he_normal')(input_tensor)\n",
    "    if do_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(num_filters, kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
    "    if do_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def unet_regression(input_size=(1024, 1024, 3), num_filters=64, depth=4, dropout=0.5, batch_norm=True, max_cores = 256):\n",
    "    # INPUT LAYER\n",
    "    inputs = Input(input_size)\n",
    "    # CONTRACTING PATH\n",
    "    conv_blocks = []\n",
    "    x = inputs\n",
    "    for i in range(depth):\n",
    "        x = conv_block(x, num_filters * (2**i), do_batch_norm=batch_norm)\n",
    "        conv_blocks.append(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        if dropout:\n",
    "            x = Dropout(dropout)(x)\n",
    "\n",
    "    # BOTTLENECK\n",
    "    x = conv_block(x, num_filters * (2**(depth)), do_batch_norm=batch_norm)\n",
    "    \n",
    "    # EXPANSIVE PATH\n",
    "    for i in reversed(range(depth)):\n",
    "        num_filters_exp = num_filters * (2**i)\n",
    "        x = UpSampling2D(size=(2, 2))(x)\n",
    "        x = concatenate([x, conv_blocks[i]], axis=3)\n",
    "        x = conv_block(x, num_filters_exp, do_batch_norm=batch_norm)\n",
    "\n",
    "\n",
    "    # OLD OUTPUT LAYER\n",
    "    # output = Conv2D(1, 1, activation='sigmoid')(x)\n",
    "    # model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    # NEW OUTPUT LAYER\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    # Adjust the number of outputs to be 3 * MAX_CORES\n",
    "    outputs = Dense(3 * max_cores, activation='linear')(x)  # 3 values for each core: x, y, and radius\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_regression(input_size=(1024, 1024, 3), num_filters=64, depth=4, dropout=0.5, batch_norm=True, max_cores = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)        [(None, 1024, 1024, 3)]      0         []                            \n",
      "                                                                                                  \n",
      " conv2d_144 (Conv2D)         (None, 1024, 1024, 64)       1792      ['input_9[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_144 (B  (None, 1024, 1024, 64)       256       ['conv2d_144[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_144 (Activation  (None, 1024, 1024, 64)       0         ['batch_normalization_144[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)         (None, 1024, 1024, 64)       36928     ['activation_144[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_145 (B  (None, 1024, 1024, 64)       256       ['conv2d_145[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_145 (Activation  (None, 1024, 1024, 64)       0         ['batch_normalization_145[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_32 (MaxPooli  (None, 512, 512, 64)         0         ['activation_145[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_48 (Dropout)        (None, 512, 512, 64)         0         ['max_pooling2d_32[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_146 (Conv2D)         (None, 512, 512, 128)        73856     ['dropout_48[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_146 (B  (None, 512, 512, 128)        512       ['conv2d_146[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_146 (Activation  (None, 512, 512, 128)        0         ['batch_normalization_146[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_147 (Conv2D)         (None, 512, 512, 128)        147584    ['activation_146[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_147 (B  (None, 512, 512, 128)        512       ['conv2d_147[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_147 (Activation  (None, 512, 512, 128)        0         ['batch_normalization_147[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_33 (MaxPooli  (None, 256, 256, 128)        0         ['activation_147[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_49 (Dropout)        (None, 256, 256, 128)        0         ['max_pooling2d_33[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_148 (Conv2D)         (None, 256, 256, 256)        295168    ['dropout_49[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_148 (B  (None, 256, 256, 256)        1024      ['conv2d_148[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_148 (Activation  (None, 256, 256, 256)        0         ['batch_normalization_148[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_149 (Conv2D)         (None, 256, 256, 256)        590080    ['activation_148[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_149 (B  (None, 256, 256, 256)        1024      ['conv2d_149[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_149 (Activation  (None, 256, 256, 256)        0         ['batch_normalization_149[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_34 (MaxPooli  (None, 128, 128, 256)        0         ['activation_149[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_50 (Dropout)        (None, 128, 128, 256)        0         ['max_pooling2d_34[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_150 (Conv2D)         (None, 128, 128, 512)        1180160   ['dropout_50[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_150 (B  (None, 128, 128, 512)        2048      ['conv2d_150[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_150 (Activation  (None, 128, 128, 512)        0         ['batch_normalization_150[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_151 (Conv2D)         (None, 128, 128, 512)        2359808   ['activation_150[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_151 (B  (None, 128, 128, 512)        2048      ['conv2d_151[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_151 (Activation  (None, 128, 128, 512)        0         ['batch_normalization_151[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_35 (MaxPooli  (None, 64, 64, 512)          0         ['activation_151[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_51 (Dropout)        (None, 64, 64, 512)          0         ['max_pooling2d_35[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_152 (Conv2D)         (None, 64, 64, 1024)         4719616   ['dropout_51[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_152 (B  (None, 64, 64, 1024)         4096      ['conv2d_152[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_152 (Activation  (None, 64, 64, 1024)         0         ['batch_normalization_152[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_153 (Conv2D)         (None, 64, 64, 1024)         9438208   ['activation_152[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_153 (B  (None, 64, 64, 1024)         4096      ['conv2d_153[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_153 (Activation  (None, 64, 64, 1024)         0         ['batch_normalization_153[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " up_sampling2d_32 (UpSampli  (None, 128, 128, 1024)       0         ['activation_153[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_32 (Concatenat  (None, 128, 128, 1536)       0         ['up_sampling2d_32[0][0]',    \n",
      " e)                                                                  'activation_151[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_154 (Conv2D)         (None, 128, 128, 512)        7078400   ['concatenate_32[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_154 (B  (None, 128, 128, 512)        2048      ['conv2d_154[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_154 (Activation  (None, 128, 128, 512)        0         ['batch_normalization_154[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_155 (Conv2D)         (None, 128, 128, 512)        2359808   ['activation_154[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_155 (B  (None, 128, 128, 512)        2048      ['conv2d_155[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_155 (Activation  (None, 128, 128, 512)        0         ['batch_normalization_155[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " up_sampling2d_33 (UpSampli  (None, 256, 256, 512)        0         ['activation_155[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_33 (Concatenat  (None, 256, 256, 768)        0         ['up_sampling2d_33[0][0]',    \n",
      " e)                                                                  'activation_149[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_156 (Conv2D)         (None, 256, 256, 256)        1769728   ['concatenate_33[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_156 (B  (None, 256, 256, 256)        1024      ['conv2d_156[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_156 (Activation  (None, 256, 256, 256)        0         ['batch_normalization_156[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_157 (Conv2D)         (None, 256, 256, 256)        590080    ['activation_156[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_157 (B  (None, 256, 256, 256)        1024      ['conv2d_157[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_157 (Activation  (None, 256, 256, 256)        0         ['batch_normalization_157[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " up_sampling2d_34 (UpSampli  (None, 512, 512, 256)        0         ['activation_157[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_34 (Concatenat  (None, 512, 512, 384)        0         ['up_sampling2d_34[0][0]',    \n",
      " e)                                                                  'activation_147[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_158 (Conv2D)         (None, 512, 512, 128)        442496    ['concatenate_34[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_158 (B  (None, 512, 512, 128)        512       ['conv2d_158[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_158 (Activation  (None, 512, 512, 128)        0         ['batch_normalization_158[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_159 (Conv2D)         (None, 512, 512, 128)        147584    ['activation_158[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_159 (B  (None, 512, 512, 128)        512       ['conv2d_159[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_159 (Activation  (None, 512, 512, 128)        0         ['batch_normalization_159[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " up_sampling2d_35 (UpSampli  (None, 1024, 1024, 128)      0         ['activation_159[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_35 (Concatenat  (None, 1024, 1024, 192)      0         ['up_sampling2d_35[0][0]',    \n",
      " e)                                                                  'activation_145[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_160 (Conv2D)         (None, 1024, 1024, 64)       110656    ['concatenate_35[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_160 (B  (None, 1024, 1024, 64)       256       ['conv2d_160[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_160 (Activation  (None, 1024, 1024, 64)       0         ['batch_normalization_160[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_161 (Conv2D)         (None, 1024, 1024, 64)       36928     ['activation_160[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_161 (B  (None, 1024, 1024, 64)       256       ['conv2d_161[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_161 (Activation  (None, 1024, 1024, 64)       0         ['batch_normalization_161[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_24 (Dense)            (None, 1024, 1024, 512)      33280     ['activation_161[0][0]']      \n",
      "                                                                                                  \n",
      " dropout_52 (Dropout)        (None, 1024, 1024, 512)      0         ['dense_24[0][0]']            \n",
      "                                                                                                  \n",
      " dense_25 (Dense)            (None, 1024, 1024, 256)      131328    ['dropout_52[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_53 (Dropout)        (None, 1024, 1024, 256)      0         ['dense_25[0][0]']            \n",
      "                                                                                                  \n",
      " dense_26 (Dense)            (None, 1024, 1024, 768)      197376    ['dropout_53[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31764416 (121.17 MB)\n",
      "Trainable params: 31752640 (121.13 MB)\n",
      "Non-trainable params: 11776 (46.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "# Assuming 'images' and 'labels' are loaded and preprocessed correctly\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    mask = tf.cast(tf.not_equal(y_true, -1), tf.float32)  # Create a mask for the padding\n",
    "    loss = MeanSquaredError()(y_true * mask, y_pred * mask)  # Apply the mask element-wise\n",
    "    return tf.reduce_sum(loss) / tf.reduce_sum(mask)  # Normalize by the number of non-padded entries\n",
    "\n",
    "\n",
    "\n",
    "# Create the U-Net model (ensure this function is defined correctly)\n",
    "model = unet_regression(input_size=(1024, 1024, 3), num_filters=32, depth=4, dropout=0.5, batch_norm=True)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss=custom_loss)\n",
    "\n",
    "# Set up callbacks for learning rate scheduling and checkpointing\n",
    "checkpoint = ModelCheckpoint('model_checkpoint.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, mode='min', min_lr=1e-6)\n",
    "\n",
    "# Split your data into training and validation sets\n",
    "# This is a simple split, consider using sklearn's train_test_split for a random split\n",
    "val_split = 0.1  # Use 10% of data for validation\n",
    "num_val_samples = int(val_split * len(images))\n",
    "train_images, val_images = images[:-num_val_samples], images[-num_val_samples:]\n",
    "train_labels, val_labels = labels[:-num_val_samples], labels[-num_val_samples:]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.0364e-04 \n",
      "Epoch 1: val_loss improved from inf to 0.00031, saving model to model_checkpoint.h5\n",
      "6/6 [==============================] - 206s 35s/step - loss: 1.0364e-04 - val_loss: 3.1125e-04 - lr: 1.0000e-04\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - ETA: 0s - loss: 1.0111e-04 \n",
      "Epoch 2: val_loss did not improve from 0.00031\n",
      "6/6 [==============================] - 213s 36s/step - loss: 1.0111e-04 - val_loss: 3.1348e-04 - lr: 1.0000e-04\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.0254e-04 \n",
      "Epoch 3: val_loss did not improve from 0.00031\n",
      "6/6 [==============================] - 209s 35s/step - loss: 1.0254e-04 - val_loss: 3.1346e-04 - lr: 1.0000e-04\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.0148e-04 \n",
      "Epoch 4: val_loss did not improve from 0.00031\n",
      "6/6 [==============================] - 214s 36s/step - loss: 1.0148e-04 - val_loss: 3.1378e-04 - lr: 1.0000e-04\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.0059e-04 \n",
      "Epoch 5: val_loss did not improve from 0.00031\n",
      "6/6 [==============================] - 219s 37s/step - loss: 1.0059e-04 - val_loss: 3.1330e-04 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images, \n",
    "    train_labels, \n",
    "    validation_data=(val_images, val_labels),\n",
    "    epochs=5,  # Set the number of epochs\n",
    "    batch_size=3,  # Set the batch size\n",
    "    callbacks=[checkpoint, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"Coordinate_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
