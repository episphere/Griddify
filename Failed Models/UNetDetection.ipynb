{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "generic_type: type \"InterpreterWrapper\" is already registered!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/gea2/Documents/medicaid/Microarray-Dearraying/UNetDetection.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/UNetDetection.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdraw\u001b[39;00m \u001b[39mimport\u001b[39;00m disk\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/UNetDetection.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/UNetDetection.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m load_img, img_to_array\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/UNetDetection.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/__init__.py:52\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mimport\u001b[39;00m autograph\n\u001b[1;32m     51\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mimport\u001b[39;00m bitwise\n\u001b[0;32m---> 52\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mimport\u001b[39;00m compat\n\u001b[1;32m     53\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mimport\u001b[39;00m config\n\u001b[1;32m     54\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/_api/v2/compat/__init__.py:37\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m\"\"\"Compatibility functions.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[39mThe `tf.compat` module contains two sets of compatibility functions.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m v1\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m v2\n\u001b[1;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m forward_compatibility_horizon\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/_api/v2/compat/v1/__init__.py:31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m autograph\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m bitwise\n\u001b[0;32m---> 31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m compat\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m config\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py:37\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m\"\"\"Compatibility functions.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[39mThe `tf.compat` module contains two sets of compatibility functions.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m v1\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m v2\n\u001b[1;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m forward_compatibility_horizon\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/_api/v2/compat/v1/compat/v1/__init__.py:48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m layers\n\u001b[1;32m     47\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m linalg\n\u001b[0;32m---> 48\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m lite\n\u001b[1;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m logging\n\u001b[1;32m     50\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m lookup\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/_api/v2/compat/v1/lite/__init__.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m constants\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m experimental\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m \u001b[39mimport\u001b[39;00m Interpreter\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m \u001b[39mimport\u001b[39;00m OpHint\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/_api/v2/compat/v1/lite/experimental/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m\"\"\"Public API for tf.lite.experimental namespace.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m authoring\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39manalyzer\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelAnalyzer \u001b[39mas\u001b[39;00m Analyzer\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m \u001b[39mimport\u001b[39;00m OpResolverType\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/_api/v2/compat/v1/lite/experimental/authoring/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m\"\"\"Public API for tf.lite.experimental.authoring namespace.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauthoring\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauthoring\u001b[39;00m \u001b[39mimport\u001b[39;00m compatible\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/lite/python/authoring/authoring.py:44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m convert\n\u001b[0;32m---> 44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m lite\n\u001b[1;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m converter_error_data_pb2\n\u001b[1;32m     46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtf_export\u001b[39;00m \u001b[39mimport\u001b[39;00m tf_export \u001b[39mas\u001b[39;00m _tf_export\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/lite/python/lite.py:48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconvert_phase\u001b[39;00m \u001b[39mimport\u001b[39;00m SubComponent\n\u001b[1;32m     47\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconvert_saved_model\u001b[39;00m \u001b[39mimport\u001b[39;00m freeze_saved_model \u001b[39mas\u001b[39;00m _freeze_saved_model\n\u001b[0;32m---> 48\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minterpreter\u001b[39;00m \u001b[39mimport\u001b[39;00m Interpreter  \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minterpreter\u001b[39;00m \u001b[39mimport\u001b[39;00m load_delegate  \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minterpreter\u001b[39;00m \u001b[39mimport\u001b[39;00m OpResolverType  \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/lite/python/interpreter.py:28\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplitext(\u001b[39m__file__\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mendswith(\n\u001b[1;32m     26\u001b[0m     os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mtflite_runtime\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minterpreter\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[1;32m     27\u001b[0m   \u001b[39m# This file is part of tensorflow package.\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minterpreter_wrapper\u001b[39;00m \u001b[39mimport\u001b[39;00m _pywrap_tensorflow_interpreter_wrapper \u001b[39mas\u001b[39;00m _interpreter_wrapper\n\u001b[1;32m     29\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m metrics\n\u001b[1;32m     30\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtf_export\u001b[39;00m \u001b[39mimport\u001b[39;00m tf_export \u001b[39mas\u001b[39;00m _tf_export\n",
      "\u001b[0;31mImportError\u001b[0m: generic_type: type \"InterpreterWrapper\" is already registered!"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.draw import disk\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_mask_from_json(json_data, shape):\n",
    "    mask = np.zeros(shape, dtype=np.float32)\n",
    "    for item in json_data:\n",
    "        rr, cc = disk((item['y'], item['x']), item['radius'], shape=shape)  # '16' is an arbitrary radius for the core\n",
    "        mask[rr, cc] = 1.0\n",
    "    return mask\n",
    "\n",
    "def load_images_and_labels(image_dir, label_dir):\n",
    "    image_files = [os.path.join(image_dir, file) for file in sorted(os.listdir(image_dir)) if file.endswith('.png')]\n",
    "    label_files = [os.path.join(label_dir, file) for file in sorted(os.listdir(label_dir)) if file.endswith('.json')]\n",
    "    \n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for image_file, label_file in zip(image_files, label_files):\n",
    "        # Load image\n",
    "        image = img_to_array(load_img(image_file, color_mode='rgb'))  # or 'rgb' if your images are colored\n",
    "        images.append(image / 255.0)  # Normalizing to [0, 1]\n",
    "\n",
    "        # Load corresponding label\n",
    "        with open(label_file, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "        mask = create_mask_from_json(json_data, shape=(1024, 1024))\n",
    "        masks.append(mask)\n",
    "\n",
    "    return np.array(images), np.array(masks).reshape(-1, 1024, 1024, 1)\n",
    "\n",
    "# Usage\n",
    "image_dir = './TMA_WSI_Padded_PNGs'\n",
    "label_dir = './TMA_WSI_Labels_updated'\n",
    "images, masks = load_images_and_labels(image_dir, label_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def verify_masks(images, masks, num_samples=3, mask_alpha=0.3):\n",
    "    \"\"\"\n",
    "    This function overlays the mask onto the image to verify position and size.\n",
    "    Parameters:\n",
    "    - images: numpy array of images.\n",
    "    - masks: numpy array of masks.\n",
    "    - num_samples: number of samples to display for verification.\n",
    "    - mask_alpha: transparency level of the mask overlay.\n",
    "    \"\"\"\n",
    "    # Set the number of images to display\n",
    "    num_samples = min(num_samples, len(images))\n",
    "\n",
    "    # Create figure to display images and masks\n",
    "    plt.figure(figsize=(20, num_samples * 10))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(num_samples, 1, i + 1)\n",
    "        plt.imshow(images[i], cmap='gray')\n",
    "        plt.imshow(masks[i].squeeze(), cmap='jet', alpha=mask_alpha)  # 'jet' colormap for the mask\n",
    "        plt.title(f'Image {i} with Mask Overlay')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function after loading your images and masks\n",
    "verify_masks(images, masks, num_samples=19, mask_alpha=0.3)\n",
    "\n",
    "save_masks(images, masks, image_dir, label_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save masks as images into the image_labels folder\n",
    "\n",
    "def save_masks(images, masks, image_dir, label_dir):\n",
    "\n",
    "    # Create the image_labels folder if it doesn't exist\n",
    "    if not os.path.exists(label_dir):\n",
    "        os.makedirs(label_dir)\n",
    "\n",
    "    # Save the masks as images\n",
    "    for i, mask in enumerate(masks):\n",
    "        mask = (mask * 255.0).astype(np.uint8)\n",
    "        mask_image = Image.fromarray(mask.squeeze())\n",
    "\n",
    "        # ensure the saved masks has the same name as their corresponding images by getting the names of the files in the image_dir\n",
    "        \n",
    "        image_name = os.listdir(image_dir)[i+1]\n",
    "       \n",
    "        mask_image.save(os.path.join(label_dir, f'{image_name}.png'))\n",
    "\n",
    "\n",
    "save_masks(images, masks, image_dir, label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D, BatchNormalization, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, num_filters, kernel_size=3, do_batch_norm=True):\n",
    "    # A conv block consists of two convolutions, each followed by a batch normalization and a relu activation.\n",
    "    x = Conv2D(num_filters, kernel_size, padding='same', kernel_initializer='he_normal')(input_tensor)\n",
    "    if do_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(num_filters, kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
    "    if do_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def unet(input_size=(1024, 1024, 3), num_filters=64, depth=4, dropout=0.5, batch_norm=True):\n",
    "    # INPUT LAYER\n",
    "    inputs = Input(input_size)\n",
    "    # CONTRACTING PATH\n",
    "    conv_blocks = []\n",
    "    x = inputs\n",
    "    for i in range(depth):\n",
    "        x = conv_block(x, num_filters * (2**i), do_batch_norm=batch_norm)\n",
    "        conv_blocks.append(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        if dropout:\n",
    "            x = Dropout(dropout)(x)\n",
    "\n",
    "    # BOTTLENECK\n",
    "    x = conv_block(x, num_filters * (2**(depth)), do_batch_norm=batch_norm)\n",
    "    \n",
    "    # EXPANSIVE PATH\n",
    "    for i in reversed(range(depth)):\n",
    "        num_filters_exp = num_filters * (2**i)\n",
    "        x = UpSampling2D(size=(2, 2))(x)\n",
    "        x = concatenate([x, conv_blocks[i]], axis=3)\n",
    "        x = conv_block(x, num_filters_exp, do_batch_norm=batch_norm)\n",
    "\n",
    "    # FINAL CONVOLUTION\n",
    "    output = Conv2D(1, 1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 1024, 1024, 3)]      0         []                            \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)          (None, 1024, 1024, 64)       1792      ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_36 (Ba  (None, 1024, 1024, 64)       256       ['conv2d_38[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_36 (Activation)  (None, 1024, 1024, 64)       0         ['batch_normalization_36[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)          (None, 1024, 1024, 64)       36928     ['activation_36[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_37 (Ba  (None, 1024, 1024, 64)       256       ['conv2d_39[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_37 (Activation)  (None, 1024, 1024, 64)       0         ['batch_normalization_37[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPoolin  (None, 512, 512, 64)         0         ['activation_37[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 512, 512, 64)         0         ['max_pooling2d_8[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)          (None, 512, 512, 128)        73856     ['dropout_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_38 (Ba  (None, 512, 512, 128)        512       ['conv2d_40[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_38 (Activation)  (None, 512, 512, 128)        0         ['batch_normalization_38[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)          (None, 512, 512, 128)        147584    ['activation_38[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_39 (Ba  (None, 512, 512, 128)        512       ['conv2d_41[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_39 (Activation)  (None, 512, 512, 128)        0         ['batch_normalization_39[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPoolin  (None, 256, 256, 128)        0         ['activation_39[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, 256, 256, 128)        0         ['max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)          (None, 256, 256, 256)        295168    ['dropout_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_40 (Ba  (None, 256, 256, 256)        1024      ['conv2d_42[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_40 (Activation)  (None, 256, 256, 256)        0         ['batch_normalization_40[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)          (None, 256, 256, 256)        590080    ['activation_40[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_41 (Ba  (None, 256, 256, 256)        1024      ['conv2d_43[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_41 (Activation)  (None, 256, 256, 256)        0         ['batch_normalization_41[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooli  (None, 128, 128, 256)        0         ['activation_41[0][0]']       \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (None, 128, 128, 256)        0         ['max_pooling2d_10[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)          (None, 128, 128, 512)        1180160   ['dropout_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (Ba  (None, 128, 128, 512)        2048      ['conv2d_44[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_42 (Activation)  (None, 128, 128, 512)        0         ['batch_normalization_42[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)          (None, 128, 128, 512)        2359808   ['activation_42[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_43 (Ba  (None, 128, 128, 512)        2048      ['conv2d_45[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_43 (Activation)  (None, 128, 128, 512)        0         ['batch_normalization_43[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooli  (None, 64, 64, 512)          0         ['activation_43[0][0]']       \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, 64, 64, 512)          0         ['max_pooling2d_11[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)          (None, 64, 64, 1024)         4719616   ['dropout_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_44 (Ba  (None, 64, 64, 1024)         4096      ['conv2d_46[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_44 (Activation)  (None, 64, 64, 1024)         0         ['batch_normalization_44[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)          (None, 64, 64, 1024)         9438208   ['activation_44[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_45 (Ba  (None, 64, 64, 1024)         4096      ['conv2d_47[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_45 (Activation)  (None, 64, 64, 1024)         0         ['batch_normalization_45[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " up_sampling2d_8 (UpSamplin  (None, 128, 128, 1024)       0         ['activation_45[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate  (None, 128, 128, 1536)       0         ['up_sampling2d_8[0][0]',     \n",
      " )                                                                   'activation_43[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)          (None, 128, 128, 512)        7078400   ['concatenate_8[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_46 (Ba  (None, 128, 128, 512)        2048      ['conv2d_48[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_46 (Activation)  (None, 128, 128, 512)        0         ['batch_normalization_46[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)          (None, 128, 128, 512)        2359808   ['activation_46[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_47 (Ba  (None, 128, 128, 512)        2048      ['conv2d_49[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_47 (Activation)  (None, 128, 128, 512)        0         ['batch_normalization_47[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " up_sampling2d_9 (UpSamplin  (None, 256, 256, 512)        0         ['activation_47[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate  (None, 256, 256, 768)        0         ['up_sampling2d_9[0][0]',     \n",
      " )                                                                   'activation_41[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)          (None, 256, 256, 256)        1769728   ['concatenate_9[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_48 (Ba  (None, 256, 256, 256)        1024      ['conv2d_50[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_48 (Activation)  (None, 256, 256, 256)        0         ['batch_normalization_48[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)          (None, 256, 256, 256)        590080    ['activation_48[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_49 (Ba  (None, 256, 256, 256)        1024      ['conv2d_51[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_49 (Activation)  (None, 256, 256, 256)        0         ['batch_normalization_49[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " up_sampling2d_10 (UpSampli  (None, 512, 512, 256)        0         ['activation_49[0][0]']       \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenat  (None, 512, 512, 384)        0         ['up_sampling2d_10[0][0]',    \n",
      " e)                                                                  'activation_39[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)          (None, 512, 512, 128)        442496    ['concatenate_10[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_50 (Ba  (None, 512, 512, 128)        512       ['conv2d_52[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_50 (Activation)  (None, 512, 512, 128)        0         ['batch_normalization_50[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)          (None, 512, 512, 128)        147584    ['activation_50[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_51 (Ba  (None, 512, 512, 128)        512       ['conv2d_53[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_51 (Activation)  (None, 512, 512, 128)        0         ['batch_normalization_51[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " up_sampling2d_11 (UpSampli  (None, 1024, 1024, 128)      0         ['activation_51[0][0]']       \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenat  (None, 1024, 1024, 192)      0         ['up_sampling2d_11[0][0]',    \n",
      " e)                                                                  'activation_37[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)          (None, 1024, 1024, 64)       110656    ['concatenate_11[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_52 (Ba  (None, 1024, 1024, 64)       256       ['conv2d_54[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_52 (Activation)  (None, 1024, 1024, 64)       0         ['batch_normalization_52[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)          (None, 1024, 1024, 64)       36928     ['activation_52[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_53 (Ba  (None, 1024, 1024, 64)       256       ['conv2d_55[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_53 (Activation)  (None, 1024, 1024, 64)       0         ['batch_normalization_53[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)          (None, 1024, 1024, 1)        65        ['activation_53[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31402497 (119.79 MB)\n",
      "Trainable params: 31390721 (119.75 MB)\n",
      "Non-trainable params: 11776 (46.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from checkpoint: unet_tma.hdf5\n",
      "Epoch 1/5\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2058 - accuracy: 0.9369  \n",
      "Epoch 1: loss improved from inf to 0.20579, saving model to unet_tma.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 820s 90s/step - loss: 0.2058 - accuracy: 0.9369 - val_loss: 0.4456 - val_accuracy: 0.8849\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1847 - accuracy: 0.9409  \n",
      "Epoch 2: loss improved from 0.20579 to 0.18473, saving model to unet_tma.hdf5\n",
      "9/9 [==============================] - 836s 93s/step - loss: 0.1847 - accuracy: 0.9409 - val_loss: 0.3623 - val_accuracy: 0.8849\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1689 - accuracy: 0.9460  \n",
      "Epoch 3: loss improved from 0.18473 to 0.16892, saving model to unet_tma.hdf5\n",
      "9/9 [==============================] - 890s 101s/step - loss: 0.1689 - accuracy: 0.9460 - val_loss: 0.3460 - val_accuracy: 0.8849\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1619 - accuracy: 0.9468  \n",
      "Epoch 4: loss improved from 0.16892 to 0.16189, saving model to unet_tma.hdf5\n",
      "9/9 [==============================] - 809s 90s/step - loss: 0.1619 - accuracy: 0.9468 - val_loss: 0.3353 - val_accuracy: 0.8849\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1488 - accuracy: 0.9497  \n",
      "Epoch 5: loss improved from 0.16189 to 0.14880, saving model to unet_tma.hdf5\n",
      "9/9 [==============================] - 911s 101s/step - loss: 0.1488 - accuracy: 0.9497 - val_loss: 0.3527 - val_accuracy: 0.8849\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# Define a learning rate schedule (example: decrease learning rate by half every 10 epochs)\n",
    "def lr_schedule(epoch, lr):\n",
    "    if epoch % 5 == 0 and epoch != 0:\n",
    "        lr = lr / 2\n",
    "    return lr\n",
    "\n",
    "# Add this to your callbacks in the training function\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule, verbose=1)\n",
    "\n",
    "\n",
    "log_dir = \"./tensorboard_logs\"\n",
    "\n",
    "def weighted_binary_crossentropy(zero_weight, one_weight):\n",
    "    def loss(y_true, y_pred):\n",
    "        bce = K.binary_crossentropy(y_true, y_pred)\n",
    "        weight_vector = y_true * one_weight + (1. - y_true) * zero_weight\n",
    "        weighted_bce = weight_vector * bce\n",
    "\n",
    "        return K.mean(weighted_bce)\n",
    "    return loss\n",
    "\n",
    "# You would then compile your model with this loss, adjusting the weights as needed for your imbalance\n",
    "def train_unet(model, images, masks, epochs=20, batch_size=1, checkpoint_path='pixel_cores.hdf5'):\n",
    "    # Define the custom loss function\n",
    "    custom_loss = weighted_binary_crossentropy(zero_weight=1, one_weight=4000)\n",
    "\n",
    "    # Check if a previous checkpoint exists\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Loading weights from checkpoint: {checkpoint_path}\")\n",
    "        # Load the model with the custom loss function\n",
    "        model = load_model(checkpoint_path, custom_objects={'loss': custom_loss})\n",
    "    else:\n",
    "        print(\"No checkpoint found. Starting training from scratch.\")\n",
    "\n",
    "    # Compile the model with the custom loss function\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss=custom_loss, metrics=['AUC', 'accuracy', 'Precision', 'Recall'])\n",
    "    model_checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    \n",
    "    # Define the TensorBoard callback\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    # Fit the model\n",
    "    history = model.fit(images, masks, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.1, callbacks=[model_checkpoint, tensorboard_callback, lr_scheduler])\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "# Using the functions\n",
    "history = train_unet(model, images, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aaron\\Documents\\GitHub\\RizzGPT\\Microarray-Dearraying\\UNetDetection.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron/Documents/GitHub/RizzGPT/Microarray-Dearraying/UNetDetection.ipynb#X11sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     plt\u001b[39m.\u001b[39mtight_layout()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron/Documents/GitHub/RizzGPT/Microarray-Dearraying/UNetDetection.ipynb#X11sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aaron/Documents/GitHub/RizzGPT/Microarray-Dearraying/UNetDetection.ipynb#X11sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m plot_training_predictions(model, images, masks)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_training_predictions(model, training_images, training_masks, num_samples=3):\n",
    "    # Make sure there is enough data for the number of samples requested\n",
    "    if num_samples > len(training_images):\n",
    "        num_samples = len(training_images)\n",
    "        print(f\"Number of available samples is less than requested. Setting num_samples to {num_samples}.\")\n",
    "\n",
    "    # Randomly select some samples from the training images and masks\n",
    "    indices = np.random.choice(len(training_images), num_samples, replace=False)\n",
    "    sample_images = np.array([training_images[i] for i in indices])\n",
    "    sample_masks = np.array([training_masks[i] for i in indices])\n",
    "\n",
    "    # Generate predictions for the sample_images\n",
    "    predicted_masks = model.predict(sample_images)\n",
    "\n",
    "    # Convert predicted masks to binary\n",
    "    binary_predicted_masks = (predicted_masks > 0.114).astype(np.uint8)\n",
    "\n",
    "    # Set up the matplotlib figure and axes, based on the number of samples\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, num_samples * 5))\n",
    "\n",
    "    if num_samples == 1:\n",
    "        axes = np.expand_dims(axes, 0)  # If only one sample, make sure axes are iterable\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        # Display original image\n",
    "        axes[i, 0].imshow(np.squeeze(sample_images[i]), cmap='gray')\n",
    "        axes[i, 0].set_title(\"Original Image\")\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        # Display true mask for the image\n",
    "        axes[i, 1].imshow(np.squeeze(sample_masks[i]), cmap='gray')\n",
    "        axes[i, 1].set_title(\"True Mask\")\n",
    "        axes[i, 1].axis('off')\n",
    "\n",
    "        # Display predicted mask for the image\n",
    "        axes[i, 2].imshow(np.squeeze(binary_predicted_masks[i]), cmap='gray')\n",
    "        axes[i, 2].set_title(\"Predicted Mask\")\n",
    "        axes[i, 2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_predictions(model, images, masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
